{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Snorkel to Extract Education of Actresses and Actors\n",
    "\n",
    "<sub>Content of this notebook was prepared by Basel Shbita (shbita@usc.edu) as part of the class <u>DSCI 558: Building Knowledge Graphs</u> during Fall 2020 at University of Southern California (USC).</sub>\n",
    "\n",
    "**Notes**: \n",
    "- You are supposed to write your code or modify our code in any cell starting with `# ** STUDENT CODE`.\n",
    "- Much content of this notebook was borrowed from Snorkel Introduction Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State-of-the-art extraction techniques require massive labeled training set but it is costly to obtain. To overcome this problem, Snorkel helps rapidly create training sets using the new data programming paradigm. To start, developers focus on writing a set of labeling functions, which are just scripts that programmatically label data. The resulting labels are noisy, but Snorkel uses a generative model to learn how to use those labeling functions to label more data. The new labeled data now can be used to train high-quality end models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In summary, in this task, you will first manually label 99 documents and use these labeled data as a development set to create your own labeling functions. Then, you will train a generative model to label 1025 documents in training set. Finally, you will train a discriminative model (Bi-LSTM) to produce your final extraction model!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a development set\n",
    "\n",
    "Before you proceed with task 1, we need to preprocess our documents using `Snorkel` utilities, parsing them into a simple hierarchy of component parts of our input data, which we refer as _contexts_. We'll also create _candidates_ out of these contexts, which are the objects we want to classify, in this case, possible mentions of schools and colleges that the cast have attended. Finally, we'll load some gold labels for evaluation.\n",
    "\n",
    "All of this preprocessed input data is saved to a database. In Snorkel, if no database is specified, then a SQLite database at `./snorkel.db` is created by default -- so no setup is needed here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** STUDENT CODE\n",
    "\n",
    "import numpy as np, os\n",
    "from pathlib import Path\n",
    "\n",
    "from snorkel.annotations import  load_gold_labels\n",
    "\n",
    "from utils import reload_external_labels, save_predicted_relations, get_gold_labels\n",
    "\n",
    "# TODO: Set location where you store your homework 5 files\n",
    "if 'HW_DIR' not in os.environ:\n",
    "    HW_DIR = Path(\"./data\")\n",
    "else:\n",
    "    HW_DIR = Path(os.environ['HW_DIR'])\n",
    "    assert HW_DIR.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initializing a `SnorkelSession`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the Corpus**\n",
    "\n",
    "Next, we load and pre-process the corpus of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.parser import TSVDocPreprocessor, CorpusParser\n",
    "\n",
    "doc_preprocessor = TSVDocPreprocessor(HW_DIR / 'cast_bios.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Running a `CorpusParser`**\n",
    "\n",
    "We'll use [Spacy](https://spacy.io/), an NLP preprocessing tool, to split our documents into sentences and tokens, and provide named entity annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "CPU times: user 11.7 s, sys: 212 ms, total: 11.9 s\n",
      "Wall time: 12 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.parser.spacy_parser import Spacy\n",
    "\n",
    "corpus_parser = CorpusParser(parser=Spacy())\n",
    "%time corpus_parser.apply(doc_preprocessor) # TSVDocPreprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use simple database queries (written in the syntax of [SQLAlchemy](http://www.sqlalchemy.org/), which Snorkel uses) to check how many documents and sentences were parsed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: 1423\n",
      "Sentences: 6933\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Document, Sentence\n",
    "\n",
    "print(\"Documents:\", session.query(Document).count()) #1423\n",
    "print(\"Sentences:\", session.query(Sentence).count()) # 6933"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generating Candidates**\n",
    "\n",
    "The next step is to extract _candidates_ from our corpus. A `Candidate` in Snorkel is an object for which we want to make a prediction. In this case, the candidates are pairs of person and organization mentioned in sentences.\n",
    "\n",
    "The [Spacy](https://spacy.io/) parser we used performs _named entity recognition_ for us. Next, we'll split up the documents into train, development, and test splits; and collect the associated sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "# helper function: kinda like namedtuple\n",
    "Education = candidate_subclass('Education', ['person', 'organization'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.candidates import Ngrams, CandidateExtractor\n",
    "from snorkel.matchers import PersonMatcher, OrganizationMatcher\n",
    "\n",
    "ngrams         = Ngrams(n_max=7) # 7 words long\n",
    "person_matcher = PersonMatcher(longest_match_only=True) # Matches Spans that are the names of people\n",
    "org_matcher    = OrganizationMatcher(longest_match_only=True) # Matches Spans that are the names of organizations\n",
    "cand_extractor = CandidateExtractor(Education, [ngrams, ngrams], [person_matcher, org_matcher])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dev sentences: 489\n",
      "Number of train sentences: 4839\n",
      "Number of test sentences: 1551\n"
     ]
    }
   ],
   "source": [
    "from utils import get_dev_doc_ids, get_test_doc_ids, number_of_people\n",
    "\n",
    "docs = session.query(Document).order_by(Document.name).all()\n",
    "\n",
    "dev_docs = get_dev_doc_ids(HW_DIR / \"cast.dev.txt\") # {'https://www.imdb.com/name/nm0000096', 'nm0000402',...}\n",
    "test_docs = get_test_doc_ids(HW_DIR / \"cast.test.txt\") # {'https://www.imdb.com/name/nm0000102', 'nm0000171',...}\n",
    "\n",
    "train_sents = set()\n",
    "dev_sents   = set()\n",
    "test_sents  = set()\n",
    "\n",
    "# predefined dev/test/train set\n",
    "for doc in docs:\n",
    "    # if a sentences mention more than five people -> unlikely contain \"people education\" relation.\n",
    "    sents = (s for s in doc.sentences if number_of_people(s) <= 5) \n",
    "    if doc.name in dev_docs:\n",
    "        dev_sents.update(sents)\n",
    "    elif doc.name in test_docs:\n",
    "        test_sents.update(sents)\n",
    "    else:\n",
    "        train_sents.update(sents)\n",
    "        \n",
    "print(\"Number of dev sentences:\", len(dev_sents)) # 489\n",
    "print(\"Number of train sentences:\", len(train_sents)) # 4839\n",
    "print(\"Number of test sentences:\", len(test_sents)) # 1551"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll apply the candidate extractor to the three sets of sentences. The results will be persisted in the database backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 27/4839 [00:00<00:18, 264.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4839/4839 [00:16<00:00, 288.31it/s]\n",
      "  7%|▋         | 32/489 [00:00<00:01, 319.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 3094\n",
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 489/489 [00:01<00:00, 278.06it/s]\n",
      "  2%|▏         | 29/1551 [00:00<00:05, 256.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 346\n",
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1551/1551 [00:05<00:00, 303.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# UDF ~ labeling function \n",
    "# iterate through train, dev, test\n",
    "for i, sents in enumerate([train_sents, dev_sents, test_sents]):\n",
    "    cand_extractor.apply(sents, split=i)\n",
    "    print(\"Number of candidates:\", session.query(Education).filter(Education.split == i).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum Up\n",
    "\n",
    "\n",
    "| dataset   | \\# sentences |\n",
    "| ----- | ------------ |\n",
    "| dev   | 668          |\n",
    "| train | 6311         |\n",
    "| test  | 2029         |\n",
    "\n",
    "\n",
    "| dataset   | \\# candidates |\n",
    "| ----- | ------------ |\n",
    "| dev (1)  | 346          |\n",
    "| train (0) | 3094         |\n",
    "| test (2) | 890         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Label 99 documents in development set\n",
    "\n",
    "In this task, you will use `SentenceNgramViewer` to label each mention. You can click the green button to mark the candidate as correct, red button to mark as incorrect. Your labeling result is automatically stored in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnotatorLabels created: 346\n",
      "AnnotatorLabels created: 186\n"
     ]
    }
   ],
   "source": [
    "# since saved development set\n",
    "\n",
    "reload_external_labels(session, HW_DIR / \"Ziheng_Gong_hw05_gold_labels.dev.json\")\n",
    "# reload_external_labels(session, HW_DIR / \"gold_labels.test.json\")\n",
    "\n",
    "# load existing labels for a development set: split 1\n",
    "gold_labels = load_gold_labels(session, annotator_name='gold', split=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number unlabeled: 346\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "require.undef('viewer');\n",
       "\n",
       "// NOTE: all elements should be selected using this.$el.find to avoid collisions with other Viewers\n",
       "\n",
       "define('viewer', [\"@jupyter-widgets/base\"], function(widgets) {\n",
       "    var ViewerView = widgets.DOMWidgetView.extend({\n",
       "        render: function() {\n",
       "            this.cids   = this.model.get('cids');\n",
       "            this.nPages = this.cids.length;\n",
       "            this.pid  = 0;\n",
       "            this.cxid = 0;\n",
       "            this.cid  = 0;\n",
       "\n",
       "            // Insert the html payload\n",
       "            this.$el.append(this.model.get('html'));\n",
       "\n",
       "            // Initialize all labels from previous sessions\n",
       "            this.labels = this.deserializeDict(this.model.get('_labels_serialized'));\n",
       "            for (var i=0; i < this.nPages; i++) {\n",
       "                this.pid = i;\n",
       "                for (var j=0; j < this.cids[i].length; j++) {\n",
       "                    this.cxid = j;\n",
       "                    for (var k=0; k < this.cids[i][j].length; k++) {\n",
       "                        this.cid = k;\n",
       "                        if (this.cids[i][j][k] in this.labels) {\n",
       "                            this.markCurrentCandidate(false);\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "            }\n",
       "            this.pid  = 0;\n",
       "            this.cxid = 0;\n",
       "            this.cid  = 0;\n",
       "\n",
       "            // Enable button functionality for navigation\n",
       "            var that = this;\n",
       "            this.$el.find(\"#next-cand\").click(function() {\n",
       "                that.switchCandidate(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-cand\").click(function() {\n",
       "                that.switchCandidate(-1);\n",
       "            });\n",
       "            this.$el.find(\"#next-context\").click(function() {\n",
       "                that.switchContext(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-context\").click(function() {\n",
       "                that.switchContext(-1);\n",
       "            });\n",
       "            this.$el.find(\"#next-page\").click(function() {\n",
       "                that.switchPage(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-page\").click(function() {\n",
       "                that.switchPage(-1);\n",
       "            });\n",
       "            this.$el.find(\"#label-true\").click(function() {\n",
       "                that.labelCandidate(true, true);\n",
       "            });\n",
       "            this.$el.find(\"#label-false\").click(function() {\n",
       "                that.labelCandidate(false, true);\n",
       "            });\n",
       "\n",
       "            // Arrow key functionality\n",
       "            this.$el.keydown(function(e) {\n",
       "                switch(e.which) {\n",
       "                    case 74: // j\n",
       "                    that.switchCandidate(-1);\n",
       "                    break;\n",
       "\n",
       "                    case 73: // i\n",
       "                    that.switchPage(-1);\n",
       "                    break;\n",
       "\n",
       "                    case 76: // l\n",
       "                    that.switchCandidate(1);\n",
       "                    break;\n",
       "\n",
       "                    case 75: // k\n",
       "                    that.switchPage(1);\n",
       "                    break;\n",
       "\n",
       "                    case 84: // t\n",
       "                    that.labelCandidate(true, true);\n",
       "                    break;\n",
       "\n",
       "                    case 70: // f\n",
       "                    that.labelCandidate(false, true);\n",
       "                    break;\n",
       "                }\n",
       "            });\n",
       "\n",
       "            // Show the first page and highlight the first candidate\n",
       "            this.$el.find(\"#viewer-page-0\").show();\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Get candidate selector for currently selected candidate, escaping id properly\n",
       "        getCandidate: function() {\n",
       "            return this.$el.find(\".\"+this.cids[this.pid][this.cxid][this.cid]);\n",
       "        },  \n",
       "\n",
       "        // Color the candidate correctly according to registered label, as well as set highlighting\n",
       "        markCurrentCandidate: function(highlight) {\n",
       "            var cid  = this.cids[this.pid][this.cxid][this.cid];\n",
       "            var tags = this.$el.find(\".\"+cid);\n",
       "\n",
       "            // Clear color classes\n",
       "            tags.removeClass(\"candidate-h\");\n",
       "            tags.removeClass(\"true-candidate\");\n",
       "            tags.removeClass(\"true-candidate-h\");\n",
       "            tags.removeClass(\"false-candidate\");\n",
       "            tags.removeClass(\"false-candidate-h\");\n",
       "            tags.removeClass(\"highlighted\");\n",
       "\n",
       "            if (highlight) {\n",
       "                if (cid in this.labels) {\n",
       "                    tags.addClass(String(this.labels[cid]) + \"-candidate-h\");\n",
       "                } else {\n",
       "                    tags.addClass(\"candidate-h\");\n",
       "                }\n",
       "            \n",
       "            // If un-highlighting, leave with first non-null coloring\n",
       "            } else {\n",
       "                var that = this;\n",
       "                tags.each(function() {\n",
       "                    var cids = $(this).attr('class').split(/\\s+/).map(function(item) {\n",
       "                        return parseInt(item);\n",
       "                    });\n",
       "                    cids.sort();\n",
       "                    for (var i in cids) {\n",
       "                        if (cids[i] in that.labels) {\n",
       "                            var label = that.labels[cids[i]];\n",
       "                            $(this).addClass(String(label) + \"-candidate\");\n",
       "                            $(this).removeClass(String(!label) + \"-candidate\");\n",
       "                            break;\n",
       "                        }\n",
       "                    }\n",
       "                });\n",
       "            }\n",
       "\n",
       "            // Extra highlighting css\n",
       "            if (highlight) {\n",
       "                tags.addClass(\"highlighted\");\n",
       "            }\n",
       "\n",
       "            // Classes for showing direction of relation\n",
       "            if (highlight) {\n",
       "                this.$el.find(\".\"+cid+\"-0\").addClass(\"left-candidate\");\n",
       "                this.$el.find(\".\"+cid+\"-1\").addClass(\"right-candidate\");\n",
       "            } else {\n",
       "                this.$el.find(\".\"+cid+\"-0\").removeClass(\"left-candidate\");\n",
       "                this.$el.find(\".\"+cid+\"-1\").removeClass(\"right-candidate\");\n",
       "            }\n",
       "        },\n",
       "\n",
       "        // Cycle through candidates and highlight, by increment inc\n",
       "        switchCandidate: function(inc) {\n",
       "            var N = this.cids[this.pid].length\n",
       "            var M = this.cids[this.pid][this.cxid].length;\n",
       "            if (N == 0 || M == 0) { return false; }\n",
       "\n",
       "            // Clear highlighting from previous candidate\n",
       "            if (inc != 0) {\n",
       "                this.markCurrentCandidate(false);\n",
       "\n",
       "                // Increment the cid counter\n",
       "\n",
       "                // Move to next context\n",
       "                if (this.cid + inc >= M) {\n",
       "                    while (this.cid + inc >= M) {\n",
       "                        \n",
       "                        // At last context on page, halt\n",
       "                        if (this.cxid == N - 1) {\n",
       "                            this.cid = M - 1;\n",
       "                            inc = 0;\n",
       "                            break;\n",
       "                        \n",
       "                        // Increment to next context\n",
       "                        } else {\n",
       "                            inc -= M - this.cid;\n",
       "                            this.cxid += 1;\n",
       "                            M = this.cids[this.pid][this.cxid].length;\n",
       "                            this.cid = 0;\n",
       "                        }\n",
       "                    }\n",
       "\n",
       "                // Move to previous context\n",
       "                } else if (this.cid + inc < 0) {\n",
       "                    while (this.cid + inc < 0) {\n",
       "                        \n",
       "                        // At first context on page, halt\n",
       "                        if (this.cxid == 0) {\n",
       "                            this.cid = 0;\n",
       "                            inc = 0;\n",
       "                            break;\n",
       "                        \n",
       "                        // Increment to previous context\n",
       "                        } else {\n",
       "                            inc += this.cid + 1;\n",
       "                            this.cxid -= 1;\n",
       "                            M = this.cids[this.pid][this.cxid].length;\n",
       "                            this.cid = M - 1;\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "\n",
       "                // Move within current context\n",
       "                this.cid += inc;\n",
       "            }\n",
       "            this.markCurrentCandidate(true);\n",
       "\n",
       "            // Push this new cid to the model\n",
       "            this.model.set('_selected_cid', this.cids[this.pid][this.cxid][this.cid]);\n",
       "            this.touch();\n",
       "        },\n",
       "\n",
       "        // Switch through contexts\n",
       "        switchContext: function(inc) {\n",
       "            this.markCurrentCandidate(false);\n",
       "\n",
       "            // Iterate context on this page\n",
       "            var M = this.cids[this.pid].length;\n",
       "            if (this.cxid + inc < 0) {\n",
       "                this.cxid = 0;\n",
       "            } else if (this.cxid + inc >= M) {\n",
       "                this.cxid = M - 1;\n",
       "            } else {\n",
       "                this.cxid += inc;\n",
       "            }\n",
       "\n",
       "            // Reset cid and set to first candidate\n",
       "            this.cid = 0;\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Switch through pages\n",
       "        switchPage: function(inc) {\n",
       "            this.markCurrentCandidate(false);\n",
       "            this.$el.find(\".viewer-page\").hide();\n",
       "            if (this.pid + inc < 0) {\n",
       "                this.pid = 0;\n",
       "            } else if (this.pid + inc > this.nPages - 1) {\n",
       "                this.pid = this.nPages - 1;\n",
       "            } else {\n",
       "                this.pid += inc;\n",
       "            }\n",
       "            this.$el.find(\"#viewer-page-\"+this.pid).show();\n",
       "\n",
       "            // Show pagination\n",
       "            this.$el.find(\"#page\").html(this.pid);\n",
       "\n",
       "            // Reset cid and set to first candidate\n",
       "            this.cid = 0;\n",
       "            this.cxid = 0;\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Label currently-selected candidate\n",
       "        labelCandidate: function(label, highlighted) {\n",
       "            var c    = this.getCandidate();\n",
       "            var cid  = this.cids[this.pid][this.cxid][this.cid];\n",
       "            var cl   = String(label) + \"-candidate\";\n",
       "            var clh  = String(label) + \"-candidate-h\";\n",
       "            var cln  = String(!label) + \"-candidate\";\n",
       "            var clnh = String(!label) + \"-candidate-h\";\n",
       "\n",
       "            // Toggle label highlighting\n",
       "            if (c.hasClass(cl) || c.hasClass(clh)) {\n",
       "                c.removeClass(cl);\n",
       "                c.removeClass(clh);\n",
       "                if (highlighted) {\n",
       "                    c.addClass(\"candidate-h\");\n",
       "                }\n",
       "                this.labels[cid] = null;\n",
       "                this.send({event: 'delete_label', cid: cid});\n",
       "            } else {\n",
       "                c.removeClass(cln);\n",
       "                c.removeClass(clnh);\n",
       "                if (highlighted) {\n",
       "                    c.addClass(clh);\n",
       "                } else {\n",
       "                    c.addClass(cl);\n",
       "                }\n",
       "                this.labels[cid] = label;\n",
       "                this.send({event: 'set_label', cid: cid, value: label});\n",
       "            }\n",
       "\n",
       "            // Set the label and pass back to the model\n",
       "            this.model.set('_labels_serialized', this.serializeDict(this.labels));\n",
       "            this.touch();\n",
       "        },\n",
       "\n",
       "        // Serialization of hash maps, because traitlets Dict doesn't seem to work...\n",
       "        serializeDict: function(d) {\n",
       "            var s = [];\n",
       "            for (var key in d) {\n",
       "                s.push(key+\"~~\"+d[key]);\n",
       "            }\n",
       "            return s.join();\n",
       "        },\n",
       "\n",
       "        // Deserialization of hash maps\n",
       "        deserializeDict: function(s) {\n",
       "            var d = {};\n",
       "            var entries = s.split(/,/);\n",
       "            var kv;\n",
       "            for (var i in entries) {\n",
       "                kv = entries[i].split(/~~/);\n",
       "                if (kv[1] == \"true\") {\n",
       "                    d[kv[0]] = true;\n",
       "                } else if (kv[1] == \"false\") {\n",
       "                    d[kv[0]] = false;\n",
       "                }\n",
       "            }\n",
       "            return d;\n",
       "        },\n",
       "    });\n",
       "\n",
       "    return {\n",
       "        ViewerView: ViewerView\n",
       "    };\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c81bfbd06a4fb7b9b1cd738f7af773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SentenceNgramViewer(cids=[[[36, 37, 219, 220, 326, 327], [159, 236, 252, 295], [51, 118, 191]], [[169, 170], […"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# if need to label\n",
    "\n",
    "from snorkel.viewer import SentenceNgramViewer\n",
    "\n",
    "gold_labels = get_gold_labels(session)\n",
    "\n",
    "labeled_sents = {lbl.candidate.person.sentence.id for lbl in gold_labels}\n",
    "\n",
    "unlabeled = [\n",
    "    x for x in session.query(Education).filter(Education.split == 1).all() \n",
    "    if x.person.sentence.id not in labeled_sents\n",
    "]\n",
    "print(\"Number unlabeled:\", len(unlabeled))\n",
    "\n",
    "SentenceNgramViewer(unlabeled, session, annotator_name=\"gold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you finish labeling, executing the cell below to **save your result** to JSON files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import save_gold_labels, save_gold_relations\n",
    "\n",
    "save_gold_labels(session, HW_DIR / \"Ziheng_Gong_hw05_gold_labels.dev.json\", split=1)\n",
    "save_gold_relations(session, HW_DIR / \"Ziheng_Gong_hw05_extracted_relation.dev.json\", split=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks 2 & 3: Define labeling functions (LFs)\n",
    "\n",
    "In these tasks, you will define your own LFs, which Snorkel uses to create noise-aware training set. Usually, you will go through a couple of iterations (create LFs, test and refine it) to come up with a good set of LFs. We provide you at the end of this section a helper to quickly see what candidates did your model fail to classify. You can refer to Snorkel tutorial or online documentation for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are free to use write any extra code to create a set of sophisticated LFs. For example, you can build a list of universities and check if it matches with your candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from snorkel.lf_helpers import (\n",
    "    get_left_tokens, get_right_tokens, get_between_tokens,\n",
    "    get_text_between, get_tagged_text, contains_token\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`c`: `<class 'snorkel.models.candidate.Education'>`\n",
    "- `c[0]`: `person`  `<class 'snorkel.models.context.Span'>`\n",
    "- `c[1]`: `organization` `<class 'snorkel.models.context.Span'>`\n",
    " \n",
    "c.person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** STUDENT CODE\n",
    "\n",
    "from snorkel.lf_helpers import test_LF\n",
    "\n",
    "verbs = {'attended', 'educated','returned', 'studied', 'enrolled', 'graduated'}\n",
    "def LF_between(c):\n",
    "    between_tokens = list(get_between_tokens(c))\n",
    "    if verbs.intersection(between_tokens) :\n",
    "#         print(c[0].get_span(),\"\\t\",between_tokens,\"\\t\",c[1].get_span())\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def LF_organization_right_movie_denial(c):\n",
    "    \"\"\"\n",
    "    if an entitiy's right token includes '(' ')' '1992' etc.\n",
    "    it's a movie entitiy, not a organization entitiy\n",
    "    \"\"\"\n",
    "    right_token = ''.join(list(get_right_tokens(c[1],window = 3)))\n",
    "    if re.match(r'\\(\\d{4}\\)',right_token):\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def LF_person_right_movie_denial(c):\n",
    "    \"\"\"\n",
    "    if an entitiy's right token includes '(' ')' '1992' etc.\n",
    "    it's a movie entitiy, not a organization entitiy\n",
    "    \"\"\"\n",
    "    right_token = ''.join(list(get_right_tokens(c[0],window = 3)))\n",
    "    if 'family' in right_token:\n",
    "        return -1\n",
    "    if re.match(r'\\(\\d{4}\\)',right_token):\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "        \n",
    "    \n",
    "schools = {'school','university','college','institute'}    \n",
    "def LF_ending_word(c):\n",
    "    span = c.organization.get_span().lower()\n",
    "    flag = -1\n",
    "    for school in schools:\n",
    "        if school in span:\n",
    "            flag = 1\n",
    "            break\n",
    "    return flag\n",
    "        \n",
    "    \n",
    "# trying to increase positve label\n",
    "def LF_between_ending(c):\n",
    "    flag = 0\n",
    "    between_tokens = list(get_between_tokens(c))\n",
    "    if LF_between(c) == 1 and LF_ending_word(c) == 1:\n",
    "        for bad_word in ['back','founded']:\n",
    "            if bad_word in between_tokens:\n",
    "                flag =  -1\n",
    "                break\n",
    "            else:\n",
    "                flag = 1\n",
    "    return flag\n",
    "\n",
    "def LF_person_right_punctuation_denial(c):\n",
    "    right_token = list(get_right_tokens(c[0],window = 1))\n",
    "    print(right_token)                       \n",
    "    return 0\n",
    "\n",
    "\n",
    "def LF_usc(c):\n",
    "    if c[1].get_span() == \"USC\":\n",
    "        person = c[0].get_span()\n",
    "        if person == 'John Singleton':\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    elif c[1].get_span() == 'Film Writing Program':\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "def LF_HarryPotter(c):\n",
    "    person = c[0].get_span()\n",
    "    school = c[1].get_span()\n",
    "    \n",
    "    if LF_between_ending(c) == 1 or LF_person_school_distance(c) == 1:\n",
    "        if person == \"Harry Potter\":\n",
    "            print(person)\n",
    "            return -1\n",
    "        if school == 'the Brothers Grimm':\n",
    "            return -1\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# My model may overfitting, trying to make up\n",
    "\n",
    "def LF_naive_distance(c):\n",
    "    distance = len(list(get_between_tokens(c)))\n",
    "    if distance >= 7:\n",
    "        return 0  \n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def LF_person_school_distance(c):\n",
    "    if LF_ending_word(c) == 1:\n",
    "        distance = len(list(get_between_tokens(c)))\n",
    "        if distance <= 3:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# tp, fp, tn, fn = test_LF(session, LF_person_school_distance, split=1, annotator_name='gold')\n",
    "\n",
    "# SentenceNgramViewer(fp, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** STUDENT CODE\n",
    "\n",
    "# Task 3 Distant supervision\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "def LF_distant_supervision(c):\n",
    "    is_school = LF_ending_word(c)\n",
    "    \n",
    "    person = c[0].get_span()\n",
    "    school = re.findall(r\"\\w+\", c[1].get_span())\n",
    "    person_pattern = '|'.join(person.split(' '))\n",
    "    school_pattern = '|'.join(school)\n",
    "\n",
    "    sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\") \n",
    "    sparql.setQuery(f\"\"\"\n",
    "        PREFIX dcterms: <http://purl.org/dc/terms/>\n",
    "        PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
    "        PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "        PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "        PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "        PREFIX xml: <http://www.w3.org/XML/1998/namespace/>\n",
    "        PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "        PREFIX dbo: <http://dbpedia.org/ontology/> \n",
    "        prefix dbp: <http://dbpedia.org/property/> \n",
    "        \n",
    "        SELECT ?person_name ?school_name\n",
    "        WHERE {{\n",
    "            ?person a dbo:Person ; \n",
    "                foaf:name ?person_name ;\n",
    "                dbo:almaMater [ foaf:name ?school_name ] .\n",
    "            FILTER(REGEX(?person_name, \"{person_pattern}\",\"i\"))\n",
    "            FILTER(REGEX(?school_name, \"{school_pattern}\",\"i\"))\n",
    "        }}\n",
    "        \"\"\")\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    try:\n",
    "        results = sparql.query().convert()\n",
    "        binding = results['results']['bindings']\n",
    "    except:\n",
    "        binding = False\n",
    "    \n",
    "    if is_school and binding:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "            \n",
    "# tp, fp, tn, fn = test_LF(session, LF_distant_supervision, split=1, annotator_name='gold')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** STUDENT CODE\n",
    "LFs = [\n",
    "    LF_between, LF_organization_right_movie_denial, LF_person_right_movie_denial, \n",
    "    LF_ending_word, LF_between_ending, LF_usc, LF_person_school_distance, LF_HarryPotter\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Applying the label functions:\n",
    "\n",
    "- run the LFs over all of our training candidates\n",
    "- producing a set of `Labels` and `LabelKeys` (just the names of the LFs) in the database.\n",
    "- by using the `LabelAnnotato`r class, a UDF which we will again run with UDFRunner . \n",
    "    - Note that this will delete any existing `Labels` and `LabelKeys` for this candidate set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 27/3094 [00:00<00:11, 267.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3094/3094 [00:11<00:00, 275.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.2 s, sys: 108 ms, total: 11.3 s\n",
      "Wall time: 11.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import LabelAnnotator\n",
    "\n",
    "np.random.seed(1701)\n",
    "\n",
    "labeler = LabelAnnotator(lfs=LFs)\n",
    "%time L_train = labeler.apply(split=0) # L_train: <class 'scipy.sparse.csr_matrix'>\n",
    "\n",
    "# L_train.get_candidate(session,0)\n",
    "# L_train.get_key(session,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Coverage: fraction of candidates that the labeling function emits a non-zero label for.\n",
    "\n",
    "- Overlap: fraction candidates that the labeling function emits a non-zero label for and that another labeling function emits a non-zero label for.\n",
    "\n",
    "- Conflict: fraction candidates that the labeling function emits a non-zero label for and that another labeling function emits a conflicting non-zero label for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_between</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.047835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_organization_right_movie_denial</th>\n",
       "      <td>1</td>\n",
       "      <td>0.196833</td>\n",
       "      <td>0.196833</td>\n",
       "      <td>0.001939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_person_right_movie_denial</th>\n",
       "      <td>2</td>\n",
       "      <td>0.153523</td>\n",
       "      <td>0.153523</td>\n",
       "      <td>0.002586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_ending_word</th>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.047835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_between_ending</th>\n",
       "      <td>4</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.000323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_usc</th>\n",
       "      <td>5</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_person_school_distance</th>\n",
       "      <td>6</td>\n",
       "      <td>0.013898</td>\n",
       "      <td>0.013898</td>\n",
       "      <td>0.006787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_HarryPotter</th>\n",
       "      <td>7</td>\n",
       "      <td>0.023594</td>\n",
       "      <td>0.023594</td>\n",
       "      <td>0.007111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    j  Coverage  Overlaps  Conflicts\n",
       "LF_between                          0  1.000000  1.000000   0.047835\n",
       "LF_organization_right_movie_denial  1  0.196833  0.196833   0.001939\n",
       "LF_person_right_movie_denial        2  0.153523  0.153523   0.002586\n",
       "LF_ending_word                      3  1.000000  1.000000   0.047835\n",
       "LF_between_ending                   4  0.016807  0.016807   0.000323\n",
       "LF_usc                              5  0.001293  0.001293   0.000000\n",
       "LF_person_school_distance           6  0.013898  0.013898   0.006787\n",
       "LF_HarryPotter                      7  0.023594  0.023594   0.007111"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train.lf_stats(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the generative model\n",
    "\n",
    "Train a model of the LFs to estimate their accuracies. \n",
    "\n",
    "Once the model is trained, we can combine the outputs of the LFs into a single, noise-aware training label set for the extractor. \n",
    "\n",
    "Intuitively, we'll model the LFs by observing how they overlap and conflict with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred cardinality: 2\n",
      "LF weights: [ 1.83763957  0.36055636  0.29243104  1.85411763  0.1006361   0.0739119\n",
      "  0.08682276  0.10717927]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "\n",
    "gen_model = GenerativeModel()\n",
    "gen_model.train(L_train, epochs=100, decay=0.95, step_size=0.1 / L_train.shape[0], reg_param=1e-6)\n",
    "\n",
    "print(\"LF weights:\", gen_model.weights.lf_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now apply the generative model to the training candidates to get the noise-aware training label set. \n",
    "\n",
    "We'll refer to these as the training marginals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll look at the distribution of the training marginals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_marginals, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.975259</td>\n",
       "      <td>0.8690</td>\n",
       "      <td>0.969705</td>\n",
       "      <td>0.845563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.670006</td>\n",
       "      <td>0.6888</td>\n",
       "      <td>0.619951</td>\n",
       "      <td>0.457440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.647399</td>\n",
       "      <td>0.6747</td>\n",
       "      <td>0.594105</td>\n",
       "      <td>0.436893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.976824</td>\n",
       "      <td>0.8716</td>\n",
       "      <td>0.972465</td>\n",
       "      <td>0.853240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.544127</td>\n",
       "      <td>0.6640</td>\n",
       "      <td>0.484508</td>\n",
       "      <td>0.360126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.541325</td>\n",
       "      <td>0.6715</td>\n",
       "      <td>0.484275</td>\n",
       "      <td>0.375480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.546118</td>\n",
       "      <td>0.6581</td>\n",
       "      <td>0.490346</td>\n",
       "      <td>0.361255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.564987</td>\n",
       "      <td>0.6609</td>\n",
       "      <td>0.506773</td>\n",
       "      <td>0.371641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Coverage  Precision    Recall\n",
       "0  0.975259    0.8690   0.969705  0.845563\n",
       "1  0.670006    0.6888   0.619951  0.457440\n",
       "2  0.647399    0.6747   0.594105  0.436893\n",
       "3  0.976824    0.8716   0.972465  0.853240\n",
       "4  0.544127    0.6640   0.484508  0.360126\n",
       "5  0.541325    0.6715   0.484275  0.375480\n",
       "6  0.546118    0.6581   0.490346  0.361255\n",
       "7  0.564987    0.6609   0.506773  0.371641"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model.learned_lf_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate model performance\n",
    "\n",
    "Now that we have learned the generative model, we will measure its performances using the provided test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnotatorLabels created: 0\n",
      "AnnotatorLabels created: 0\n"
     ]
    }
   ],
   "source": [
    "# Load test-set first\n",
    "reload_external_labels(session, HW_DIR / \"gold_labels.test.json\")\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 23/346 [00:00<00:01, 222.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 346/346 [00:01<00:00, 227.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.917\n",
      "Neg. class accuracy: 0.97\n",
      "Precision            0.524\n",
      "Recall               0.917\n",
      "F1                   0.667\n",
      "----------------------------------------\n",
      "TP: 11 | FP: 10 | TN: 324 | FN: 1\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "L_dev = labeler.apply_existing(split=1)\n",
    "tp, fp, tn, fn = gen_model.error_analysis(session, L_dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get detailed statistics of LFs learned by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>Empirical Acc.</th>\n",
       "      <th>Learned Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_between</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.078035</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>319</td>\n",
       "      <td>0.945087</td>\n",
       "      <td>0.975023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_organization_right_movie_denial</th>\n",
       "      <td>1</td>\n",
       "      <td>0.225434</td>\n",
       "      <td>0.225434</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.671650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_person_right_movie_denial</th>\n",
       "      <td>2</td>\n",
       "      <td>0.147399</td>\n",
       "      <td>0.147399</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.647399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_ending_word</th>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.078035</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>323</td>\n",
       "      <td>0.962428</td>\n",
       "      <td>0.976957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_between_ending</th>\n",
       "      <td>4</td>\n",
       "      <td>0.028902</td>\n",
       "      <td>0.028902</td>\n",
       "      <td>0.008671</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.546235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_usc</th>\n",
       "      <td>5</td>\n",
       "      <td>0.017341</td>\n",
       "      <td>0.017341</td>\n",
       "      <td>0.017341</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.540879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_person_school_distance</th>\n",
       "      <td>6</td>\n",
       "      <td>0.023121</td>\n",
       "      <td>0.023121</td>\n",
       "      <td>0.008671</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.545510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_HarryPotter</th>\n",
       "      <td>7</td>\n",
       "      <td>0.028902</td>\n",
       "      <td>0.028902</td>\n",
       "      <td>0.008671</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.565138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    j  Coverage  Overlaps  Conflicts  TP  FP  \\\n",
       "LF_between                          0  1.000000  1.000000   0.078035   8  15   \n",
       "LF_organization_right_movie_denial  1  0.225434  0.225434   0.002890   0   0   \n",
       "LF_person_right_movie_denial        2  0.147399  0.147399   0.011561   0   0   \n",
       "LF_ending_word                      3  1.000000  1.000000   0.078035  10  11   \n",
       "LF_between_ending                   4  0.028902  0.028902   0.008671   7   0   \n",
       "LF_usc                              5  0.017341  0.017341   0.017341   1   0   \n",
       "LF_person_school_distance           6  0.023121  0.023121   0.008671   6   2   \n",
       "LF_HarryPotter                      7  0.028902  0.028902   0.008671   8   2   \n",
       "\n",
       "                                    FN   TN  Empirical Acc.  Learned Acc.  \n",
       "LF_between                           4  319        0.945087      0.975023  \n",
       "LF_organization_right_movie_denial   0   78        1.000000      0.671650  \n",
       "LF_person_right_movie_denial         0   51        1.000000      0.647399  \n",
       "LF_ending_word                       2  323        0.962428      0.976957  \n",
       "LF_between_ending                    0    3        1.000000      0.546235  \n",
       "LF_usc                               0    5        1.000000      0.540879  \n",
       "LF_person_school_distance            0    0        0.750000      0.545510  \n",
       "LF_HarryPotter                       0    0        0.800000      0.565138  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_dev.lf_stats(session, L_gold_dev, gen_model.learned_lf_stats()['Accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might want to look at some examples in one of the error buckets to improve your LFs. For example, below is one of the false negatives that we did not correctly label as true mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from snorkel.viewer import SentenceNgramViewer\n",
    "\n",
    "SentenceNgramViewer(fp, session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Training an End Extraction Model\n",
    "\n",
    "In this final task, we'll use the noisy training labels we generated to train our end extraction model. In particular, we will be training a Bi-LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cands = session.query(Education).filter(Education.split == 0).order_by(Education.id).all()\n",
    "dev_cands   = session.query(Education).filter(Education.split == 1).order_by(Education.id).all()\n",
    "test_cands  = session.query(Education).filter(Education.split == 2).order_by(Education.id).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "L_gold_dev  = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try tuning the hyper-parameters below to get your best F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM] Training model\n",
      "[LSTM] n_train=3094  #epochs=20  batch size=70\n",
      "[LSTM] Epoch 1 (7.03s)\tAverage loss=0.341581\tDev F1=0.00\n",
      "[LSTM] Epoch 2 (14.57s)\tAverage loss=0.148260\tDev F1=0.00\n",
      "[LSTM] Epoch 3 (22.72s)\tAverage loss=0.121620\tDev F1=0.00\n",
      "[LSTM] Epoch 4 (30.46s)\tAverage loss=0.098135\tDev F1=0.00\n",
      "[LSTM] Epoch 5 (38.01s)\tAverage loss=0.082487\tDev F1=0.00\n",
      "[LSTM] Epoch 6 (45.68s)\tAverage loss=0.070111\tDev F1=0.00\n",
      "[LSTM] Epoch 7 (53.48s)\tAverage loss=0.062683\tDev F1=8.70\n",
      "[LSTM] Epoch 8 (61.86s)\tAverage loss=0.066948\tDev F1=9.09\n",
      "[LSTM] Epoch 9 (70.48s)\tAverage loss=0.056856\tDev F1=22.22\n",
      "[LSTM] Epoch 10 (79.18s)\tAverage loss=0.052254\tDev F1=22.22\n",
      "[LSTM] Epoch 11 (88.15s)\tAverage loss=0.051226\tDev F1=22.22\n",
      "[LSTM] Epoch 12 (96.78s)\tAverage loss=0.049263\tDev F1=34.48\n",
      "[LSTM] Epoch 13 (105.41s)\tAverage loss=0.050772\tDev F1=30.30\n",
      "[LSTM] Epoch 14 (114.40s)\tAverage loss=0.050248\tDev F1=43.75\n",
      "[LSTM] Epoch 15 (123.38s)\tAverage loss=0.046915\tDev F1=45.16\n",
      "[LSTM] Epoch 16 (132.26s)\tAverage loss=0.046644\tDev F1=41.38\n",
      "[LSTM] Epoch 17 (140.90s)\tAverage loss=0.059323\tDev F1=34.48\n",
      "[LSTM] Model saved as <LSTM>\n",
      "[LSTM] Epoch 18 (149.75s)\tAverage loss=0.047929\tDev F1=38.71\n",
      "[LSTM] Model saved as <LSTM>\n",
      "[LSTM] Epoch 19 (159.04s)\tAverage loss=0.047308\tDev F1=31.25\n",
      "[LSTM] Epoch 20 (168.60s)\tAverage loss=0.045213\tDev F1=38.71\n",
      "[LSTM] Training done (169.10s)\n",
      "[LSTM] Loaded model <LSTM>\n"
     ]
    }
   ],
   "source": [
    "# ** STUDENT CODE\n",
    "\n",
    "# TODO: tune your hyper-parameters for best results\n",
    "\n",
    "from snorkel.learning.pytorch import LSTM\n",
    "\n",
    "train_kwargs = {\n",
    "    'lr':            0.001, # learning rate of the model\n",
    "    'embedding_dim': 50,   # size of the feature vector\n",
    "    'hidden_dim':    50,   # number of nodes in each layer in the model\n",
    "    'n_epochs':      20,   # number of training epochs\n",
    "    'dropout':       0.2,  # dropout rate (during learning)\n",
    "    'batch_size':    70,   # training batch size\n",
    "    'seed':          1701\n",
    "}\n",
    "\n",
    "lstm = LSTM(n_threads=None)\n",
    "lstm.train(train_cands, train_marginals, X_dev=dev_cands, Y_dev=L_gold_dev, **train_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Report performance of your final extractor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.406, Recall: 0.542, F1 Score: 0.464\n"
     ]
    }
   ],
   "source": [
    "p, r, f1 = lstm.score(test_cands, L_gold_test)\n",
    "print(\"Prec: {0:.3f}, Recall: {1:.3f}, F1 Score: {2:.3f}\".format(p, r, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.542\n",
      "Neg. class accuracy: 0.978\n",
      "Precision            0.406\n",
      "Recall               0.542\n",
      "F1                   0.464\n",
      "----------------------------------------\n",
      "TP: 13 | FP: 19 | TN: 847 | FN: 11\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn = lstm.error_analysis(session, test_cands, L_gold_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your new model to extract relation in testing documents, and save it to JSON files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** STUDENT CODE\n",
    "\n",
    "# TODO: change to your name\n",
    "save_predicted_relations(HW_DIR / \"Firstname_Lastname_hw05_extracted_relation.test.json\", test_cands, lstm.predictions(test_cands))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
